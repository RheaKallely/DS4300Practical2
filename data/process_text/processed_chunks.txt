--- Chunk 1 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction

--- Chunk 2 ---
mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envpro

--- Chunk 3 ---
##d neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import

--- Chunk 4 ---
folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete

--- Chunk 5 ---
p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 6 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction

--- Chunk 7 ---
docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport

--- Chunk 8 ---
configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes

--- Chunk 9 ---
##er compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose

--- Chunk 10 ---
folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete

--- Chunk 11 ---
filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 12 ---
raydirectedpperson return p

--- Chunk 13 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction

--- Chunk 14 ---
language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _

--- Chunk 15 ---
mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envpro

--- Chunk 16 ---
configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes

--- Chunk 17 ---
##d neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import

--- Chunk 18 ---
create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerele

--- Chunk 19 ---
folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete

--- Chunk 20 ---
##ase _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title

--- Chunk 21 ---
p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 22 ---
raydirectedpperson return p

--- Chunk 23 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes

--- Chunk 24 ---
create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 25 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes

--- Chunk 26 ---
##er compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 27 ---
raydirectedpperson return p

--- Chunk 28 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes

--- Chunk 29 ---
##d neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title

--- Chunk 30 ---
p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 31 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 32 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 33 ---
ds 4300 neo4j mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune neo4j query language plugins cypher neo4js graph query language created 2011 goal sqlequivalent language graph databases provides visual way matching patterns relationships nodesconnect _ toothernodes apoc plugin awesome procedures cypher addon library provides hundreds procedures functions graph data science plugin provides efficient implementations common graph algorithms like ones talked yesterday neo4j docker compose docker compose supports multicontainer management setup declarative using yaml dockercomposeyaml file services volumes networks etc 1 command used start stop scale number services one time provides consistent method producing identical environment well works machine interaction mostly via command line dockercomposeyaml services neo4j container _ name neo4j image neo4jlatest ports 74747474 76877687 environment neo4j _ authneo4jneo4j _ password neo4j _ apoc _ export _ file _ enabledtrue neo4j _ apoc _ import _ file _ enabledtrue neo4j _ apoc _ import _ file _ use _ _ neo4j _ _ configtrue neo4j _ pluginsapoc graphdatascience volumes neo4j _ dbdatadata neo4j _ dblogslogs neo4j _ dbimportvarlibneo4jimport neo4j _ dbpluginsplugins never put secrets docker compose file use env files env files env files stores collection environment variables good way keep environment variables different platforms separate envlocal envdev envprod neo4j _ passwordabc123 env file docker compose commands test docker cli properly installed run docker version major docker commands docker compose docker compose docker compose docker compose start docker compose stop docker compose build docker compose build nocache localhost7474 neo4j browser httpsneo4jcomdocsbrowsermanualcurrentvisualtour localhost7474 login inserting data creating nodes create user name alice birthplace paris create user name bob birthplace london create user name carol birthplace london create user name dave birthplace london create user name eve birthplace rome adding edge variable names create user name alice birthplace paris create user name bob birthplace london match aliceuser namealice match bobuser name bob create aliceknows since 20221201bob note relationships directed neo4j matching users born london match usruser birthplace london return usrname usrbirthplace download dataset move import folder clone repo httpsgithubcompacktpublishinggraphdatasciencewithneo4j chapter02data data repo unzip netflixzip file copy netflix _ titlescsv following folder put docker compose file neo4j _ dbneo4j _ dbimport importing data basic data importing load csv headers filenetflix _ titlescsv line createmovie id lineshow _ id title linetitle releaseyear linerelease _ year type following cypher editor neo4j browser loading csvs general syntax load csv headers filefile _ in _ import _ foldercsv line fieldterminator stuffs line importing directors time load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name create person name trimdirector _ name generates duplicate person nodes director direct 1 movie importing directors merged match pperson delete p load csv headers filenetflix _ titlescsv line splitlinedirector directors _ list unwind directors _ list director _ name merge person name director _ name adding edges load csv headers filenetflix _ titlescsv line match mmovie id lineshow _ id splitlinedirector directors _ list unwind directors _ list director _ name match pperson name director _ name create pdirectedm gut check lets check movie titled ray match mmovie title raydirectedpperson return p

--- Chunk 34 ---
raydirectedpperson return p

--- Chunk 35 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 36 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 37 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 38 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 39 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 40 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 41 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 42 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 43 ---
31925 459 pm avltreerotationspng 30595956 httpsmarkfontenotnetwpcontentuploads202409avltreerotationspng 11

--- Chunk 44 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st

--- Chunk 45 ---
city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno

--- Chunk 46 ---
1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodb

--- Chunk 47 ---
##customerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order

--- Chunk 48 ---
rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mfl

--- Chunk 49 ---
##ixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders

--- Chunk 50 ---
project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 51 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st

--- Chunk 52 ---
green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno

--- Chunk 53 ---
##ty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty

--- Chunk 54 ---
14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demo

--- Chunk 55 ---
##customerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order

--- Chunk 56 ---
literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match

--- Chunk 57 ---
##2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mflixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _

--- Chunk 58 ---
imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesag

--- Chunk 59 ---
project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 60 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st

--- Chunk 61 ---
streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 q

--- Chunk 62 ---
city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno

--- Chunk 63 ---
##ty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty

--- Chunk 64 ---
1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodb

--- Chunk 65 ---
120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields

--- Chunk 66 ---
##customerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order

--- Chunk 67 ---
except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit

--- Chunk 68 ---
rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mfl

--- Chunk 69 ---
##2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mflixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _

--- Chunk 70 ---
##ixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders

--- Chunk 71 ---
id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 72 ---
project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 73 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty

--- Chunk 74 ---
120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mfl

--- Chunk 75 ---
##ixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 76 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty

--- Chunk 77 ---
14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match

--- Chunk 78 ---
##2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mflixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 79 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty

--- Chunk 80 ---
1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit

--- Chunk 81 ---
rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mflixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 82 ---
project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 83 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mfl

--- Chunk 84 ---
##ixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 85 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mfl

--- Chunk 86 ---
year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mflixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 87 ---
import pymongo bsonjson _ util import dumps update uri username password uri mongodbusernamepasswordlocalhost27017 client pymongomongoclienturi mflixdb clientmflix setup demodb 2 collections demodbcustomersdrop demodbordersdrop customers custid c13 name cruise address street 201 main st city st louis mo zipcode 63101 rating 750 custid c25 name streep address street 690 river st city hanover zipcode 02340 rating 690 custid c31 name b pitt address street 360 mountain ave city st louis mo zipcode 63101 custid c35 name j roberts address street 420 green st city boston zipcode 02115 rating 565 custid c37 name hanks address street 120 harbor blvd city boston zipcode 02115 rating 750 custid c41 name r duvall address street 150 market st city st louis mo zipcode 63101 rating 640 custid c47 name loren address street via del corso city rome italy rating 625 orders orderno 1001 custid c41 order _ date 20170429 ship _ date 20170503 items itemno 347 qty 5 price 1999 itemno 193 qty 2 price 2889 orderno 1002 custid c13 order _ date 20170501 ship _ date 20170503 items itemno 460 qty 95 price 10099 itemno 680 qty 150 price 875 orderno 1003 custid c31 order _ date 20170615 ship _ date 20170616 items itemno 120 qty 2 price 8899 itemno 460 qty 3 price 9999 orderno 1004 custid c35 order _ date 20170710 ship _ date 20170715 items itemno 680 qty 6 price 999 itemno 195 qty 4 price 3500 orderno 1005 custid c37 order _ date 20170830 items itemno 460 qty 2 price 9998 itemno 347 qty 120 price 2200 itemno 780 qty 1 price 150000 itemno 375 qty 2 price 14998 orderno 1006 custid c41 order _ date 20170902 ship _ date 20170904 items itemno 680 qty 51 price 2598 itemno 120 qty 65 price 8500 itemno 460 qty 120 price 9998 orderno 1007 custid c13 order _ date 20170913 ship _ date 20170920 items itemno 185 qty 5 price 2199 itemno 680 qty 1 price 2050 orderno 1008 custid c13 order _ date 20171013 items itemno 460 qty 20 price 9999 demodbcustomersinsert _ manycustomers demodbordersinsert _ manyorders numcustomers demodbcustomerscount _ documents numorders demodborderscount _ documents printfthere numcustomers customers numorders orders key _ id attribute automatically returned unless explicitly say remove select name rating customers data demodbcustomersfind name1 rating1 printdumpsdata indent2 without _ id field select name rating customers data demodbcustomersfind name1 rating1 _ id0 printdumpsdata indent2 fields except specific ones returned every customer return fields except _ id address data demodbcustomersfind _ id 0 address 0 printdumpsdata indent2 equivalent sql like operator select name rating customers name like regular expression explanation match beginning line match literal character beginning line case match single character except newline match zero occurrences previous character case data demodbcustomersfindname regex _ id 0 name 1 rating1 printdumpsdata indent2 sorting limiting select name rating customers order rating limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortratinglimit2 printdumpsdata indent2 sorting desc order select name rating customers order rating desc limit 2 data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1limit2 printdumpsdata indent2 providing 2 sort keys data demodbcustomersfind _ id 0 name 1 rating1 sortrating 1 name 1limit2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mfl

--- Chunk 88 ---
##2 printdumpsdata indent2 aggregates pymongo aggregation uses _ pipelines _ pipeline sequence stages documents proceed different stages used match project sort limit unwind group lookup match c mflixdbmoviesaggregate match year lte 1920 printdumpsc indent4 match project c mflixdbmoviesaggregate match year lte 1920 project _ id0 title 1 cast 1 printdumpsc indent4 match project limit sort c mflixdbmoviesaggregate match year lte 1920 sort title 1 limit 5 project _ id0 title 1 cast 1 printdumpsc indent4 unwind c mflixdbmoviesaggregate match year lte 1920 sort imdbrating 1 limit 5 unwind cast project _ id0 title 1 cast 1 rating imdbrating printdumpsc indent4 grouping average imdb rating movies year sort data year c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort _ id 1 printdumpsc indent 2 average imdb rating movies year sort data avg rating decreasing order c mflixdbmoviesaggregate group _ id release year year avg rating avg imdbrating sort avg rating 1 _ id 1 printdumpsc indent 2 lookup data demodbcustomersaggregate lookup orders localfield custid foreignfield custid orders project _ id 0 address 0 printdumpsdata indent 2 reformatting queries match match year lte 1920 limit limit 5 project project _ id0 title 1 cast 1 rating imdbrating agg mflixdbmoviesaggregatematch limit project printdumpsagg indent2

--- Chunk 89 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountab

--- Chunk 90 ---
##c printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 print

--- Chunk 91 ---
##redis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 92 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountab

--- Chunk 93 ---
highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen

--- Chunk 94 ---
mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get

--- Chunk 95 ---
##isredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 96 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountab

--- Chunk 97 ---
##redishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values

--- Chunk 98 ---
##c printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 print

--- Chunk 99 ---
mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get

--- Chunk 100 ---
##redis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 101 ---
_ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 102 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get

--- Chunk 103 ---
_ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 104 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get

--- Chunk 105 ---
##isredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 106 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get

--- Chunk 107 ---
##redis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 108 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 109 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 110 ---
ds 4300 redis python mark fontenot phd northeastern university redispy redispy standard client python maintained redis company github repo redisredispy 4300 conda environment pip install redis connecting server docker deployment host could localhost 127001 port port mapping given created container probably default 6379 db database 015 want connect decode _ responses data comes back server bytes setting true converter decodes strings import redis redis _ client redisredishostlocalhost port6379 db2 decode _ responsestrue redis command list full list use filter get command particular data structure youre targeting list hash set etc redispy documentation next slides meant exhaustive list commands highlights check documentation complete list string commands r represents redis client object rsetclickcountabc 0 val rgetclickcountabc rincrclickcountabc ret _ val rgetclickcountabc printfclick count ret _ val string commands 2 r represents redis client object redis _ clientmsetkey1 val1 key2 val2 key3 val3 printredis _ clientmgetkey1 key2 key3 returns list val1 val2 val3 string commands 3 set mset setex msetnx setnx get mget getex getdel incr decr incrby decrby strlen append list commands 1 create list key names values mark sam nick redis _ clientrpushnames mark sam nick prints mark sam nick printredis _ clientlrangenames 0 1 list commands 2 lpush lpop lset lrem rpush rpop lrange llen lpos commands include moving elements lists popping multiple lists time etc hash commands 1 redis _ clienthsetusersession123 mappingfirst sam last uelle company redis age 30 prints name sam surname uelle company redis age 30 printredis _ clienthgetallusersession123 hash commands 2 hset hget hgetall hkeys hdel hexists hlen hstrlen redis pipelines helps avoid multiple related calls server less network overhead r redisredisdecode _ responsestrue pipe rpipeline range5 pipesetfseati fi set _ 5 _ result pipeexecute printset _ 5 _ result true true true true true pipe rpipeline chain pipeline commands together get _ 3 _ result pipegetseat0getseat3getseat4execute printget _ 3 _ result 0 3 4 redis context redis ml simplified example source httpswwwfeatureformcompostfeaturestoresexplainedthethreecommonarchitectures redis dsml source httpsmadewithmlcomcoursesmlopsfeaturestore

--- Chunk 111 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical

--- Chunk 112 ---
networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs

--- Chunk 113 ---
elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data

--- Chunk 114 ---
streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 115 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical

--- Chunk 116 ---
apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content

--- Chunk 117 ---
network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully

--- Chunk 118 ---
highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon reko

--- Chunk 119 ---
streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 120 ---
services

--- Chunk 121 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical

--- Chunk 122 ---
continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure

--- Chunk 123 ---
networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs

--- Chunk 124 ---
network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully

--- Chunk 125 ---
elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data

--- Chunk 126 ---
managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier

--- Chunk 127 ---
streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 128 ---
allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 129 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully

--- Chunk 130 ---
managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 131 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully

--- Chunk 132 ---
highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 133 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully

--- Chunk 134 ---
elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 135 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 136 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 137 ---
ds 4300 aws introduction mark fontenot phd northeastern university amazon web services leading cloud platform 200 different services available globally available via massive networks regions availability zones massive data centers based payasyouuse cost model theoretically cheaper renting rackspaceservers data center theoretically history aws originally launched 2006 2 services s3 ec2 2010 services expanded include simpledb elastic block store relational database service dynamodb cloudwatch simple workflow cloudfront availability zones others amazon competitions big prizes spur adoption aws early days theyve continuously innovated always introducing new services ops dev analytics etc 200 services aws service categories cloud models iaas infrastructure service contains basic services needed build infrastructure paas platform service remove need manage infrastructure get right deploying app saas software service provide full software apps run managed another partyvendor cloud models httpsbluexpnetappcomiaas shared responsibility model aws aws responsibilities security cloud security physical infrastructure infra network keep data centers secure control access maintain power availability hvac etc monitor maintain physical networking equipment global infraconnectivity hypervisor host oss manage virtualization layer used aws compute services maintaining underlying host oss services maintaining managed services keep infra date functional maintain server software patching etc shared responsibility model client client responsibilities security cloud control datacontent client controls data classified encrypted shared implement enforce appropriate datahandling policies access management iam properly configure iam users roles policies enforce principle least privilege manage selfhosted apps associated oss ensure network security vpc handle compliance governance policies procedures aws global infrastructure regions distinct geographical areas useast1 uswest 1 etc availability zones azs region multiple azs roughly equiv isolated data centers edge locations locations cdn types caching services allows content closer end user httpsawsamazoncomaboutawsglobalinfrastructure compute services httpsawsamazoncomproductscompute vmbased ec2 ec2 spot elastic cloud compute containerbased ecs elastic container service ecr elastic container registry eks elastic kubernetes service fargate serverless container service serverless aws lambda storage services httpsawsamazoncomproductsstorage amazon s3 simple storage service object storage buckets highly scalable different storage classes amazon efs elastic file system simple serverless elastic setandforget file system amazon ebs elastic block storage highperformance block storage service amazon file cache highspeed cache datasets stored anywhere aws backup fully managed policybased service automate data protection compliance apps aws database services relational amazon rds amazon aurora keyvalue amazon dynamodb inmemory amazon memorydb amazon elasticache document amazon documentdb compat mongodb graph amazon neptune analytics services amazon athena analyze petabyte scale data lives s3 example amazon emr elastic mapreduce access apache spark hive presto etc aws glue discover prepare integrate data amazon redshift data warehousing service amazon kinesis realtime data streaming amazon quicksight cloudnative bireporting tool ml ai services amazon sagemaker fullymanaged ml platform including jupyter nbs build train deploy ml models aws ai services w pretrained models amazon comprehend nlp amazon rekognition imagevideo analysis amazon textract text extraction amazon translate machine translation important services data analyticsengineering ec2 lambda amazon s3 amazon rds dynamodb aws glue amazon athena amazon emr amazon redshift aws free tier allows gain handson experience subset services 12 months service limitations apply well amazon ec2 750 hoursmonth specific oss instance sizes amazon s3 5gb 20k gets 2k puts amazon rds 750 hoursmonth db use within certain limits many free services

--- Chunk 138 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo st

--- Chunk 139 ---
##rozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failure

--- Chunk 140 ---
##unreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation

--- Chunk 141 ---
results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary index

--- Chunk 142 ---
##es supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtore

--- Chunk 143 ---
##source exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues

--- Chunk 144 ---
queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist

--- Chunk 145 ---
three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 146 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo st

--- Chunk 147 ---
handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network

--- Chunk 148 ---
event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple

--- Chunk 149 ---
alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv

--- Chunk 150 ---
results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary index

--- Chunk 151 ---
inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type

--- Chunk 152 ---
##79 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objects

--- Chunk 153 ---
##ent 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguous

--- Chunk 154 ---
queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist

--- Chunk 155 ---
list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds

--- Chunk 156 ---
##00 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 157 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo st

--- Chunk 158 ---
locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations

--- Chunk 159 ---
##rozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failure

--- Chunk 160 ---
event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple

--- Chunk 161 ---
##unreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation

--- Chunk 162 ---
comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions ca

--- Chunk 163 ---
results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary index

--- Chunk 164 ---
##ching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 63

--- Chunk 165 ---
##es supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtore

--- Chunk 166 ---
##79 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objects

--- Chunk 167 ---
##source exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues

--- Chunk 168 ---
##structures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs

--- Chunk 169 ---
queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist

--- Chunk 170 ---
bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs32

--- Chunk 171 ---
three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 172 ---
##00 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 173 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple

--- Chunk 174 ---
comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtore

--- Chunk 175 ---
##source exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs32

--- Chunk 176 ---
##00 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 177 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple

--- Chunk 178 ---
alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type

--- Chunk 179 ---
##79 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist

--- Chunk 180 ---
list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 181 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple

--- Chunk 182 ---
##unreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 63

--- Chunk 183 ---
##es supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs

--- Chunk 184 ---
queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 185 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtore

--- Chunk 186 ---
##source exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 187 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtore

--- Chunk 188 ---
maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 189 ---
ds 4300 nosql kv dbs mark fontenot phd northeastern university material used permission dr rachlin thanks distributed dbs acid pessimistic concurrency acid transactions focuses data safety considered pessimistic concurrency model assumes one transaction protect transactions iow assumes something go wrong conflicts prevented locking resources transaction complete read write locks write lock analogy borrowing book library one else see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation deeper dive optimistic concurrency transactions obtain locks data read write optimistic assumes conflicts unlikely occur even conflict everything still ok add last update timestamp version number columns every table read changing check end transaction see transaction caused modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems conflicts arise handled rolling back rerunning transaction notices conflict optimistic concurrency works well allows higher concurrency high conflict systems rolling back rerunning transactions encounter conflict less efficient locking scheme pessimistic model might preferable nosql nosql first used 1998 carlo strozzi describe relational database system use sql common modern meaning sql sometimes thought nonrelational dbs idea originally developed part response processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem 2 3 following consistency every user db identical view data given instant availability event failure database system remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network partitions consistency partition tolerance system responds data distrib system always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data acid alternative distrib systems base basically available guarantees availability data per cap response failureunreliable data inconsistent changing state system appears work time acid alternative distrib systems base soft state state system could change time even wo input changes could result eventual consistency data stores dont writeconsistent replicas dont mutually consistent acid alternative distrib systems base eventual consistency system eventually become consistent writes eventually stop nodesreplicas updated categories nosql dbs review first keyvalue databases key value stores key value keyvalue stores designed around simplicity data model extremely simple comparatively tables rdbms complex lends simple crud ops api creation key value stores key value keyvalue stores designed around speed usually deployed inmemory db retrieving value given key typically o1 op bc hash tables similar data structs used hood concept complex queries joins slow things key value stores key value keyvalue stores designed around scalability horizontal scaling simple add nodes typically concerned eventual consistency meaning distributed environment guarantee nodes eventually converge value kv ds use cases edaexperimentation results store store intermediate results data preprocessing eda store experiment testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval model training prediction model monitoring store key metrics performance model example realtime inferencing kv swe use cases storing session information everything current session stored via single put post retrieved single get fast user profiles preferences user info could obtained single get operation language tz product ui preferences shopping cart data cart data tied user needs available across browsers machines sessions caching layer front diskbased database redis db redis remote directory server open source inmemory database sometimes called data structure store primarily kv store used models graph spatial full text search vector time series dbenginescom ranking kv stores redis considered inmemory database system supports durability data essentially saving snapshots disk specific intervals b appendonly file journal changes used rollforward failure originally developed 2009 c fast 100000 set ops second rich collection commands handle complex data secondary indexes supports lookup key redis data types keys usually strings binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting redis docker docker desktop search redis pullrun latest image see optional settings add 6379 ports expose port connect normally would expose redis port security reasons prod environment major security hole notice didnt set password connecting datagrip file new data source redis give data source name make sure port 6379 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtore

--- Chunk 190 ---
##79 test connection redis database interaction redis provides 16 databases default numbered 0 15 name associated direct interaction redis set commands related setting getting kv pairs variations many language libraries available well foundation data type string sequence bytes text serialized objects bin arrays simplest data type maps string another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views rate limiting initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select different database basic commands set somevalue 0 incr somevalue increment 1 incrby somevalue 10 increment 10 decr somevalue decrement 1 decrby somevalue 5 decrement 5 incr parses value int increments adds value setnx key value sets value key key already exist hash type value kv entry collection fieldvalue pairs use cases used represent basic objectsstructures number fieldvalue pairs per hash 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking sessions one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 returned list type value kv pair linked lists string values use cases implementation stacks queues queue management message passing queues producerconsumer model logging systems easy keep chronological order build social media streamsfeeds message history chat application batch processing queueing set tasks executed sequentially later time linked lists crash course sequential data structure linked nodes instead contiguously allocated memory node points next element list except last one points nilnull o1 insert new value front insert new value end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support json standard uses jsonpath syntax parsingnavigating json document internally stored binary treestructure fast access sub elements set type unordered collection unique strings members use cases track unique items ip addresses visiting site page screen primitive relation set students ds4300 access control lists users permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300

--- Chunk 191 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs

--- Chunk 192 ---
unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing

--- Chunk 193 ---
graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 194 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs

--- Chunk 195 ---
4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singles

--- Chunk 196 ---
##s vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 197 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs

--- Chunk 198 ---
systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bf

--- Chunk 199 ---
unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing

--- Chunk 200 ---
##s vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 201 ---
graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 202 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 203 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 204 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 205 ---
graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 206 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 207 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 208 ---
ds 4300 introduction graph data model mark fontenot phd northeastern university material referenced graph algorithms practical examples apache spark neo4j needham hodler oreilly press 2019 graph database data model based graph data structure composed nodes edges edges connect nodes uniquely identified contain properties eg name occupation etc supports queries based graphoriented operations traversals shortest path lots others graphs show social networks yes things like instagram also modeling social interactions fields like psychology sociology web big graph pages nodes connected hyperlinks edges chemical biological data systems biology genetics etc interaction relationships chemistry basics graphs graph theory graph labeled property graph composed set node vertex objects relationship edge objects labels used mark node part group properties attributes think kv pairs exist nodes relationships nodes associated relationships ok edges connected nodes permitted example 2 labels person car 4 relationship types drives owns lives _ with married _ to properties paths path ordered sequence nodes connected edges nodes edges repeated 1 2 3 6 5 4 ex 1 2 6 5 path 1 2 6 2 3 flavors graphs connected vs disconnected path two nodes graph weighted vs unweighted edge weight property important algorithms directed vs undirected relationships edges define start end node acyclic vs cyclic graph contains cycles connected vs disconnected weighted vs unweighted directed vs undirected cyclic vs acyclic sparse vs dense trees types graph algorithms pathfinding pathfinding finding shortest path two nodes one exists probably common operation shortest means fewest edges lowest weight average shortest path used monitor efficiency resiliency networks minimum spanning tree cycle detection maxmin flow types pathfinding bfs vs dfs shortest path types graph algorithms centrality community detection centrality determining nodes important network compared nodes ex social network influencers community detection evaluate clustering partitioning nodes graph tendency strengthen break apart centrality famous graph algorithms dijkstras algorithm singlesource shortest path algo positively weighted graphs algorithm similar dijkstras added feature using heuristic guide traversal pagerank measures importance node within graph based number incoming relationships importance nodes incoming relationships neo4j graph database system supports transactional analytical processing graphbased data relatively new class nosql dbs considered schema optional one imposed supports various types indexing acid compliant supports distributed computing similar microsoft cosmodb amazon neptune

--- Chunk 209 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree

--- Chunk 210 ---
anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total

--- Chunk 211 ---
number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree

--- Chunk 212 ---
always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n

--- Chunk 213 ---
cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm

--- Chunk 214 ---
ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees

--- Chunk 215 ---
certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance

--- Chunk 216 ---
condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t

--- Chunk 217 ---
##3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add

--- Chunk 218 ---
new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted

--- Chunk 219 ---
imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary

--- Chunk 220 ---
correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree

--- Chunk 221 ---
height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2

--- Chunk 222 ---
##j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change as

--- Chunk 223 ---
##ymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 224 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree

--- Chunk 225 ---
vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second

--- Chunk 226 ---
##ion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height

--- Chunk 227 ---
control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left

--- Chunk 228 ---
always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n

--- Chunk 229 ---
definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieve

--- Chunk 230 ---
algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height

--- Chunk 231 ---
rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl

--- Chunk 232 ---
certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance

--- Chunk 233 ---
property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduth

--- Chunk 234 ---
circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image l

--- Chunk 235 ---
second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees

--- Chunk 236 ---
new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted

--- Chunk 237 ---
node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left

--- Chunk 238 ---
##25 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search

--- Chunk 239 ---
back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h

--- Chunk 240 ---
height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2

--- Chunk 241 ---
##h 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship

--- Chunk 242 ---
##l trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 243 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree

--- Chunk 244 ---
7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recurs

--- Chunk 245 ---
anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total

--- Chunk 246 ---
##ion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height

--- Chunk 247 ---
number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree

--- Chunk 248 ---
tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindben

--- Chunk 249 ---
always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n

--- Chunk 250 ---
##ding definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible

--- Chunk 251 ---
cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm

--- Chunk 252 ---
algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height

--- Chunk 253 ---
ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees

--- Chunk 254 ---
cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty

--- Chunk 255 ---
certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance

--- Chunk 256 ---
subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right

--- Chunk 257 ---
condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t

--- Chunk 258 ---
circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image l

--- Chunk 259 ---
##3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add

--- Chunk 260 ---
##r rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance

--- Chunk 261 ---
new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted

--- Chunk 262 ---
note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 319

--- Chunk 263 ---
imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary

--- Chunk 264 ---
##25 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search

--- Chunk 265 ---
correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree

--- Chunk 266 ---
tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 m

--- Chunk 267 ---
height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2

--- Chunk 268 ---
##h 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree av

--- Chunk 269 ---
##j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change as

--- Chunk 270 ---
##l trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 271 ---
##ymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 272 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height

--- Chunk 273 ---
tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm

--- Chunk 274 ---
ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right

--- Chunk 275 ---
circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted

--- Chunk 276 ---
imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 m

--- Chunk 277 ---
##h 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 278 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height

--- Chunk 279 ---
control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieve

--- Chunk 280 ---
algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance

--- Chunk 281 ---
property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees

--- Chunk 282 ---
new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search

--- Chunk 283 ---
back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship

--- Chunk 284 ---
##l trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 285 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height

--- Chunk 286 ---
number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible

--- Chunk 287 ---
cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty

--- Chunk 288 ---
certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image l

--- Chunk 289 ---
##3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 319

--- Chunk 290 ---
imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 m

--- Chunk 291 ---
height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 292 ---
##ymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 293 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm

--- Chunk 294 ---
ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted

--- Chunk 295 ---
imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 296 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm

--- Chunk 297 ---
##s perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted

--- Chunk 298 ---
note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 299 ---
ics 46 spring 2022 news course reference schedule project guide notes examples reinforcement exercises grade calculator alex ics 46 spring 2022 notes examples avl trees must care binary search tree balancing weve seen previously performance characteristics binary search trees vary rather wildly theyre mainly dependent shape tree height tree key determining factor definition binary search trees restrict keys allowed present nodes smaller keys left subtrees larger keys right subtrees specify restriction trees shape meaning perfectly legal binary search trees containing keys 1 2 3 4 5 6 7 yet legal one better height first tree called perfect binary tree smaller height second called degenerate tree two shapes represent two extremes best worst possible shapes binary search tree containing seven keys course small number keys like shape number keys grows distinction two tree shapes becomes increasingly vital whats degenerate shape isnt even necessarily rare edge case get start empty tree add keys already order surprisingly common scenario realworld programs example one obvious algorithm generating unique integer keys care theyre unique generate sequentially whats bad degenerate tree anyway looking picture degenerate tree intuition already telling something amiss particular tilt head 45 degrees right look like linked lists perception accident behave like except theyre complicated boot analytical perspective three results give us pause every time perform lookup degenerate binary search tree take time possible youll reach every node tree youre done n grows heavy burden bear implement lookup recursively might also using memory might end many n frames runtime stack one every recursive call ways mitigate example kinds carefullywritten recursion programming languages including c avoid runtime stack growth recurse still sign potential trouble time take build degenerate tree also prohibitive start empty binary search tree add keys order long take first key add go directly root could think taking single step creating node second key add require look root node take one step right could think taking two steps subsequent key add require one step one total number steps would take add n keys would determined sum 1 2 3 n sum well see several times throughout course equal nn 1 2 total number steps build entire tree would θn2 overall n gets large tree would hideously expensive build every subsequent search would painful well general situation need sure avoid else probably consider data structure binary search tree worst case simply much burden bear n might get large find way control trees shape carefully force remain balanced well fine question course importantly whether keeping cost low enough doesnt outweigh benefit aiming perfection best goal us shoot would maintain perfection words every time insert key binary search tree would ideally still perfect binary tree case wed know height tree would always θlog n commensurate effect performance 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 17 however consider goal problem emerges almost immediately following perfect binary trees definition perfect binary trees pictured 1 3 7 15 nodes respectively possible perfect shapes binary trees number nodes problem though lies fact valid perfect binary tree 2 nodes 4 5 6 8 9 10 11 12 13 14 nodes generally impossible us guarantee binary search tree always perfect definition theres simply way represent numbers keys first things first well need relax definition perfection accommodate every possible number keys might want store complete binary trees somewhat relaxed notion perfection something called complete binary tree defined follows complete binary tree height h binary tree h 0 left right subtrees empty h 0 one two things true left subtree perfect binary tree height h 1 right subtree complete binary tree height h 1 left subtree complete binary tree height h 1 right subtree perfect binary tree height h 2 bit mindbending definition actually leads conceptually simple result every level complete binary tree every node could possibly present except last level might missing nodes missing nodes nodes far left possible following complete binary trees furthermore possible complete binary trees numbers nodes arrangement say 6 keys besides one shown would violate definition weve seen height perfect binary tree θlog n stretch see height complete binary tree θlog n well well accept via intuition proceed complete binary tree would great goal us attain could keep shape binary search trees complete would always binary search trees height θlog n cost maintaining completeness trouble course need algorithm maintaining completeness go trouble trying figure one consider whether even worth time deduce cost maintaining completeness even havent figured algorithm yet one example demonstrates big problem suppose binary search tree left complete definition wanted insert key 1 would need algorithm would transform tree left tree right tree right certainly complete would outcome wed want consider would take every key tree move matter algorithm used would still move every key n keys tree would take ωn time moving n keys takes least linear time even best possible algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm

--- Chunk 300 ---
algorithm moving work still get done worst case maintaining completeness single insertion requires ωn time unfortunately time ought spending maintaining balance means well need come compromise often case learn design algorithms willingness tolerate imperfect result thats still good enough uses often lead algorithm much faster one achieves perfect result would good enough result good balance condition overall goal lookups insertions removals binary search tree require olog n time every case rather letting degrade worstcase behavior need decide balance condition say need understand shape considered well 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 27 enough balanced purposes even perfect good balance condition two properties height binary search tree meeting condition θlog n takes olog n time rebalance tree insertions removals words guarantees height tree still logarithmic give us logarithmictime lookups time spent rebalancing wont exceed logarithmic time would otherwise spend insertion removal tree logarithmic height cost wont outweigh benefit coming balance condition like tall task stand shoulders giants came us definition helping guide us toward understanding whether weve found looking compromise avl trees wellknown approaches maintaining binary search trees state nearbalance meets notion good balance condition one called avl tree well explore others outside scope course include redblack trees meet definition good splay trees dont always meet definition good meet amortized basis well stick one solution problem avl trees avl trees might called nearly balanced binary search trees certainly arent perfectlybalanced possible nonetheless achieve goals weve decided maintaining logarithmic height logarithmic cost makes binary search tree nearly balanced enough considered avl tree core concept embodied something called avl property say node binary search tree avl property heights left right subtrees differ 1 words tolerate certain amount imbalance heights subtrees slightly different hopes efficiently maintain since going comparing heights subtrees theres one piece background need consider recall height tree length longest path definition height tree root node empty subtrees would zero tree thats totally empty maintain clear pattern relative tree heights well say height empty tree 1 means node say childless left child right child would still considered balanced leads us finally definition avl tree avl tree binary search tree nodes avl property binary trees two avl two thing keep mind avl matter squinting tree deciding whether looks balanced theres precise definition two trees dont meet definition fail meet least one node marked diagrams dashed square doesnt avl property avl trees definition required meet balance condition every operation every time insert remove key every node tree avl property meet requirement need restructure tree periodically essentially detecting correcting imbalance whenever wherever happens need rearrange tree ways improve shape without losing essential ordering property binary search tree smaller keys toward left larger ones toward right rotations rebalancing avl trees achieved using called rotations used proper times efficiently improve shape tree altering handful pointers kinds rotations first understand work focus attention use first kind rotation called rotation takes tree left turns tree right circle b written single node containing single key triangles t1 t2 t3 written arbitrary subtrees may empty may contain number nodes binary search trees 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 37 important remember trees binary search trees rotation doesnt harm ordering keys nodes subtrees t1 t2 t3 maintain appropriate positions relative keys b keys t1 smaller keys t2 larger smaller b keys t3 larger b performing rotation would simple matter adjusting pointers notably constant number pointers matter many nodes tree means rotation would run θ1 time bs parent would point used point b right child would b instead root t2 bs left child would root t2 instead second kind rotation rr rotation makes similar adjustment note rr rotation mirror image rotation third kind rotation lr rotation makes adjustment thats slightly complicated lr rotation requires five pointer updates instead three still constant number changes runs θ1 time finally rl rotation mirror image lr rotation understand mechanics rotations work one step closer understanding avl trees rotations arent arbitrary theyre used specifically correct imbalances detected insertions removals insertion algorithm 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 47 inserting key avl tree starts way insertion binary search tree perform lookup find key already tree youre done keys binary search tree must unique lookup terminates without key found add new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance

--- Chunk 301 ---
new node appropriate leaf position lookup ended problem adding new node introduced possibility imbalance example suppose started avl tree inserted key 35 binary search tree insertion would give us result resulting tree avl tree node containing key 40 avl property difference heights subtrees 2 left subtree height 1 right subtree empty height 1 answer lies following algorithm perform normal insertion process work way back tree position added node could quite simple insertion done recursively compare heights left right subtrees node differ 1 choose rotation fix imbalance note comparing heights left right subtrees would quite expensive didnt already know solution problem node store height ie height subtree rooted cheaply updated every insertion removal unwind recursion rotation chosen considering two links along path node imbalance heading back toward inserted node wondering names rr lr rl come answer mystery two links left perform rotation rooted imbalance two links right perform rr rotation rooted imbalance first link left second right perform lr rotation rooted imbalance first link right second left perform rl rotation rooted imbalance shown one rotations rr lr rl correct imbalance brought inserting key case wed perform lr rotation first two links leading 40 toward 35 left right rooted 40 would correct imbalance tree would rearranged look like compare diagram describing lr rotation node containing 40 c node containing 30 node containing 35 b empty left subtree node containing 30 t1 empty left subtree node containing 35 t2 empty right subtree node containing 35 t3 empty right subtree node containing 40 t4 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 57 rotation see wed expect node b example contained 35 root newlyrotated subtree node example contained 30 left child root newlyrotated subtree node c example contained 40 right child root newlyrotated subtree four subtrees t1 t2 t3 t4 empty still empty note tree balanced rotation accident single rotation rr lr rl thats necessary correct imbalance introduced insertion algorithm removal algorithm removals somewhat similar insertions sense would start usual binary search tree removal algorithm find correct imbalances recursion unwinds key difference removals require one rotation correct imbalances still require rotations path back root removal occurred generally olog n rotations asymptotic analysis key question height avl tree n nodes answer θlog n certain lookups insertions removals take olog n time sure lookups would olog n theyre binary search tree doesnt avl property height tree θlog n lookups run olog n time insertions removals despite slightly complicated avl tree work traversing single path tree potentially way leaf position way back length longest path thats height tree θlog n know none paths longer insertions removals take olog n time left key question height avl tree n nodes youre curious feel free assume want know keep reading height avl tree n nodes optional answer revolves around noting many nodes minimum could binary search tree height n still avl tree turns avl trees height n 2 minimum number nodes share similar property avl tree height h 2 minimum number nodes consists root node two subtrees one avl tree height h 1 minimum number nodes avl tree height h 2 minimum number nodes given observation write recurrence describes number nodes minimum avl tree height h m0 1 height 0 minimum number nodes 1 root node children m1 2 height 1 minimum number nodes 2 root node one child mh 1 mh 1 mh 2 repeated substitution technique learned previously isnt good way try solve particular recurrence prove something interesting quite easily know sure avl trees larger heights bigger minimum number nodes avl trees smaller heights thats fairly selfexplanatory means sure 1 mh 1 mh 2 given conclude following mh 2mh 2 use repeated substitution technique determine lower bound recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j could prove induction j well accept faith let j h2 2h2mh h 2h2m0 mh 2h2 weve shown minimum number nodes present avl tree height h least 2h2 reality actually gives us something useful work use result figure really interested opposite height avl tree n nodes mh 2h2 log2mh h2 2 log2mh h finally see avl trees height h minimum number nodes height 2 log2n n number nodes tree avl trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change as

--- Chunk 302 ---
##l trees minimum number nodes relationship number nodes height even better though 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 67 reasons weve seen previously know relationship number nodes height binary tree never better logarithmic ultimately see height avl tree n nodes θlog n reality turns bound lower 2 log2n something akin 144 log2n even avl trees minimum number nodes though proof involved doesnt change asymptotic result 31925 452 pm ics 46 spring 2022 notes examples avl trees httpsicsucieduthorntonics46notesavltrees 77

--- Chunk 303 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast

--- Chunk 304 ---
random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific

--- Chunk 305 ---
id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 306 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast

--- Chunk 307 ---
##s cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk

--- Chunk 308 ---
worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table

--- Chunk 309 ---
##ber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 310 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast

--- Chunk 311 ---
##x bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison

--- Chunk 312 ---
random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific

--- Chunk 313 ---
worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table

--- Chunk 314 ---
id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 315 ---
would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 316 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table

--- Chunk 317 ---
would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 318 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table

--- Chunk 319 ---
##ber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 320 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table

--- Chunk 321 ---
id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 322 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 323 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 324 ---
ds 4300 large scale information storage retrieval foundations mark fontenot phd northeastern university searching searching common operation performed database system sql select statement arguably versatile complex baseline efficiency linear search start beginning list proceed element element find youre looking get last element havent found searching record collection values attributes single entity instance row table collection set records entity type table trivially stored sequential order like list search key value attribute entity type could 1 attribute lists records record takes x bytes memory n records need nx bytes memory contiguously allocated list nx bytes allocated single chunk memory linked list record needs x bytes additional space 1 2 memory addresses individual records linked together type chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked memory addresses linked list extra storage memory address pros cons arrays faster random access slow inserting anywhere end linked lists faster inserting anywhere list slower random access insert 2nd record records records 5 records moved make space insert 2nd record observations arrays fast random access slow random insertions linked lists slow random access fast random insertions binary search input array values sorted order target value output location index target located value indicating target found def binary _ searcharr target left right 0 lenarr 1 left right mid left right 2 arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 c g p r z target mid since target arrmid reset right mid 1 left right c g p r z target mid left right time complexity linear search best case target found first element 1 comparison worst case target array n comparisons therefore worst case linear search time complexity binary search best case target found mid 1 comparison inside loop worst case target array log2 n comparisons therefore worst case binary search olog2n time complexity back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient back database searching assume data stored disk column ids value searching specific id fast want search specific specialval option linear scan column cant store data disk sorted id specialval time data would duplicated space inefficient need external data structure support faster searching specialval linear scan arsenal array tuples specialval rownumber sorted specialval could use binary search quickly locate particular specialval find corresponding row table every insert table would like inserting sorted array slow linked list tuples specialval rownumber sorted specialval searching specialval would slow linear scan required inserting table would theoretically quick also add list really talking database indexes something fast insert fast search binary search tree binary tree every node left subtree less parent every node right subtree greater parent image httpscoursesgraingerillinoiseducs225sp2019notesbst board

--- Chunk 325 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds

--- Chunk 326 ---
##4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 327 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds

--- Chunk 328 ---
id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 329 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds

--- Chunk 330 ---
##4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 331 ---
##4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 332 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 333 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 334 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 335 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 336 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 337 ---
ds 4300 mongodb pymongo mark fontenot phd northeastern university pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 clientds4300 collection dbmycollection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id find movies 2000 bsonjson _ util import dumps find movies released 2000 movies _ 2000 dbmoviesfindyear 2000 print results printdumpsmovies _ 2000 indent 2 jupyter time activate ds4300 conda venv python environment install pymongo pip install pymongo install jupyter lab python environment pip install jupyterlab download unzip zip file contains 2 jupyter notebooks terminal navigate folder unzipped files run jupyter lab

--- Chunk 338 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2

--- Chunk 339 ---
inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th

--- Chunk 340 ---
left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil

--- Chunk 341 ---
return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child z

--- Chunk 342 ---
##s place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root

--- Chunk 343 ---
x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n

--- Chunk 344 ---
n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 345 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2

--- Chunk 346 ---
##er ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing

--- Chunk 347 ---
##er traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd

--- Chunk 348 ---
else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively

--- Chunk 349 ---
return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child z

--- Chunk 350 ---
return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x

--- Chunk 351 ---
##s z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question

--- Chunk 352 ---
27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4

--- Chunk 353 ---
n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 354 ---
##x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 355 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2

--- Chunk 356 ---
objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preord

--- Chunk 357 ---
inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th

--- Chunk 358 ---
##er traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd

--- Chunk 359 ---
left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil

--- Chunk 360 ---
maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19

--- Chunk 361 ---
return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child z

--- Chunk 362 ---
20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm delete

--- Chunk 363 ---
##s place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root

--- Chunk 364 ---
##s z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question

--- Chunk 365 ---
x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n

--- Chunk 366 ---
consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1

--- Chunk 367 ---
n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 368 ---
4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 369 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd

--- Chunk 370 ---
maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root

--- Chunk 371 ---
x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 372 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd

--- Chunk 373 ---
else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x

--- Chunk 374 ---
##s z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 375 ---
##x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 376 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd

--- Chunk 377 ---
left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm delete

--- Chunk 378 ---
##s place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1

--- Chunk 379 ---
n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 380 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root

--- Chunk 381 ---
x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 382 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root

--- Chunk 383 ---
righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 384 ---
chapter 12 binary search trees binary search tree binary tree special property called bstproperty given follows nodes x belongs left subtree x key less key x belongs right subtree x key greater key x assume keys bst pairwise distinct node following attributes p left right pointers parent left child right child respectively key key stored node 1 example 4 2 3 6 5 12 9 8 11 15 19 20 7 2 traversal nodes bst traversal mean visiting nodes graph traversal strategies speciﬁed ordering three objects visit current node left subtree right subtree assume left subtree always comes right subtree three strategies 1 inorder ordering left subtree current node right subtree 2 preorder ordering current node left subtree right subtree 3 postorder ordering left subtree right subtree current node 3 inorder traversal pseudocode recursive algorithm takes input pointer tree executed inorder traversal tree traversal prints key node visited inorderwalkx 1 x nil return 2 inorderwalkleftx 3 print keyx 4 inorderwalkrightx write similar pseudocode preorder postorder 4 preorder postorder inorder 2 1 3 1 1 2 2 3 3 4 2 3 6 5 12 9 8 11 15 19 20 7 outcome inorder traversal bst postorder traversal preorder traversal 5 inorder traversal gives 2 3 4 5 6 7 8 9 11 12 15 19 20 preorder traversal gives 7 4 2 3 6 5 12 9 8 11 19 15 20 postorder traversal gives 3 2 5 6 4 8 11 9 15 20 19 12 7 inorder travel bst ﬁnds keys nondecreasing order 6 operations bst 1 searching key assume key subtree key searched given input well take full advantage bstproperty suppose node node key searched search otherwise key current node either strictly smaller key searched strictly greater key searched former case bst property keys th left subtree strictly less key searched means need search left subtree thus examine right subtree latter case symmetry examine right subtree 7 algorithm k key searched x start node bstsearchx k 1 x 2 nil 3 keyy k return 4 else keyy k righty 5 else lefty 6 return found 8 example search 8 7 4 2 6 9 13 11 nil running time search 9 2 maximum minimum ﬁnd minimum identify leftmost node ie farthest node reach following left branches ﬁnd maximum identify rightmost node ie farthest node reach following right branches bstminimumx 1 x nil return empty tree 2 x 3 lefty nil lefty 4 return keyy bstmaximumx 1 x nil return empty tree 2 x 3 righty nil righty 4 return keyy 10 3 insertion suppose need insert node z k keyz using binary search ﬁnd nil replacing z break bstproperty 11 bstinsertx z k 1 x nil return error 2 x 3 true 4 keyy k 5 z lefty 6 else z righty 7 z nil break 8 9 keyy k lefty z 10 else rightpy z 12 4 successor predecessor successor respectively predecessor key k search tree smallest respectively largest key belongs tree strictly greater respectively less k idea ﬁnding successor given node x x right child successor minimum right subtree x otherwise successor parent farthest node reached x following right branches backward 13 example 4 2 3 6 5 12 9 8 11 15 19 20 7 25 23 14 algorithm bstsuccessorx 1 rightx nil 2 rightx 3 lefty nil lefty 4 return 5 else 6 x 7 rightpx x px 8 px nil return px 9 else return successor 15 predecessor found similarly roles left right exchanged roles maximum minimum exchanged node successor undeﬁned running time successor algorithm 16 5 deletion suppose want delete node z 1 z children replace z nil 2 z one child promote unique child zs place 3 z two children identify zs successor call successor either leaf right child promote zs place treat loss using one two solutions 17 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 9 13 11 8 4 2 3 5 6 1 3 2 4 7 9 13 11 8 5 6 9 13 11 8 7 10 10 10 5 6 1 3 2 4 7 9 13 11 8 5 6 1 3 2 4 13 11 9 10 18 algorithm algorithm deletes z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root

--- Chunk 385 ---
##s z bst bstdeletet z 1 leftz nil rightz nil 2 z 3 else bstsuccessorz 4 node thats actually removed 5 two children 6 lefty nil 7 x lefty 8 else x righty 9 x node thats moving ys position 10 x nil px py 11 px reset x isnt nil 12 resetting unnecessary x nil 19 algorithm contd 13 py nil roott x 14 root x becomes root 15 otherwise following 16 else leftpy 17 leftpy x 18 left child parent 19 set parents left child x 20 else rightpy x 21 right child parent 22 set parents right child x 23 z 24 keyz keyy 25 move data z 27 return 20 summary [UNK] analysis theorem binary search tree height h search minimum maximum successor predecessor insert delete made run oh time 21 randomly built bst suppose insert n distinct keys initially empty tree assuming n permutations equally likely occur average height tree study question consider process constructing tree inserting order randomly selected n distinct keys initially empty tree actually values keys matter matters position inserted key n keys 22 process construction view process follows key x keys selected uniformly random inserted tree keys inserted keys greater x go right subtree x keys smaller x go left subtree thus height tree thus constructed one plus larger height left subtree height right subtree 23 random variables n number keys xn height tree n keys yn 2xn want upper bound eyn n 2 eyn 1 n n x i1 2emaxyi1 yni emaxyi1 yni eyi1 yni eyi1 eyni collecting terms eyn 4 n n1 x i1 eyi 24 analysis claim n 1 eyn 1 4 n3 3 prove induction n base case ey1 20 1 induction step eyn 4 n n1 x i1 eyi using fact n1 x i0 3 3 n 3 4 eyn 4 n 1 4 n 3 4 eyn 1 4 n 3 3 25 jensens inequality function f convex x x λ 0 λ 1 fλx 1 λy λfx 1 λfy jensens inequality states random variables x convex function f fex efx let x xn fx 2x efx eyn 2exn 1 4 n 3 3 righthand side n 33 taking log sides exn olog n thus average height randomly build bst olog n 26

--- Chunk 386 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores

--- Chunk 387 ---
data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves

--- Chunk 388 ---
movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights

--- Chunk 389 ---
directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 390 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores

--- Chunk 391 ---
strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via

--- Chunk 392 ---
developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepost

--- Chunk 393 ---
##godbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection

--- Chunk 394 ---
directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 395 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores

--- Chunk 396 ---
return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview

--- Chunk 397 ---
data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves

--- Chunk 398 ---
developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepost

--- Chunk 399 ---
movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights

--- Chunk 400 ---
##inserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schema

--- Chunk 401 ---
directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 402 ---
##optional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 403 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepost

--- Chunk 404 ---
##inserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 405 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepost

--- Chunk 406 ---
##godbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 407 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepost

--- Chunk 408 ---
movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 409 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 410 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 411 ---
foundations largescale information storage retrieval searching common database operation sql select complex versatile statement linear search baseline efficiency starts beginning list proceeds element element ends target found last element reached database concepts record row table collection attribute values entity collection table set records entity type search key value attribute one attributes memory allocation lists contiguously allocated list nx bytes allocated single chunk fast random access slow insertions linked list requires x bytes per record plus space pointers fast insertions slow random access binary search requires sorted data algorithm find middle element mid target return index mid target search right half else search left half time complexity linear search worst case binary search olog n worst case database searching indexing searching primary key eg id fast searching nonindexed attribute eg specialval requires linear scan indexing strategies sorted array tuples specialval row number fast search slow insertions linked list tuples specialval row number slow search fast insertions binary search tree bst balances fast insertions searches document databases mongodb document database nosql database stores data structured documents uses json javascript object notation format advantages simple flexible scalable wellsuited applications using jsonxml transport layer json vs bson json humanreadable lightweight uses namevalue pairs ordered lists bson binary json binaryencoded json supports additional data types date binarydata designed efficiency traversal storage optimization use document databases avoids impedance mismatch objectoriented programming relational databases documents selfdescribing making flexible dynamic data storage mongodb overview developed 2007 former doubleclick engineers mongodb atlas 2016 fully managed cloud service structure database collections documents documents collection dont require fixed schema mongodb features rich query support full crud operations indexing supports primary secondary indices replication automatic failover via replica sets load balancing builtin interacting mongodb cli tools mongosh mongodb shell mongodb compass gui query examples dbusersfindname davos seaworth filters documents name dbmoviesfind rated pg pg13 retrieves movies specific ratings dbmoviesfind countries mexico imdbrating gte 7 finds movies released mexico imdb 7 mongodb python pymongo connecting mongodb pymongo import mongoclient client mongoclientmongodbuser _ namepwlocalhost27017 selecting collection db clientds4300 collection dbmycollection inserting document post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id counting documents count collectioncount _ documents introduction graph data models graph database graphbased data model using nodes entities edges relationships nodes properties metadata nodes edges enables graphbased queries traversals shortest paths etc graphs used social networks modeling relationships web pages connected via hyperlinks biology chemistry interaction modeling graph theory basics labeled property graph nodes labels grouping nodesedges properties keyvalue pairs edges must always connect nodes graph terminology path sequence connected nodes repetition connected graph path exists two nodes weighted graph edges weights directed graph relationships direction acyclic graph cycles graph algorithms pathfinding shortest path nodes eg dijkstras algorithm minimum spanning tree cycle detection maxmin flow centrality community detection centrality identifies influential nodes eg social media influencers community detection clustering partitioning nodes famous graph algorithms 1 dijkstras algorithm singlesource shortest path weighted graphs 2 algorithm like dijkstras uses heuristics efficiency 3 pagerank ranks nodes based incoming links neo4j graph database system schemaoptional nosql database supports acid transactions distributed computing competes amazon neptune microsoft cosmosdb

--- Chunk 412 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using

--- Chunk 413 ---
gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app st

--- Chunk 414 ---
##write data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 415 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using

--- Chunk 416 ---
storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit sci

--- Chunk 417 ---
##latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust

--- Chunk 418 ---
response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 419 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using

--- Chunk 420 ---
starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3

--- Chunk 421 ---
gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app st

--- Chunk 422 ---
##latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust

--- Chunk 423 ---
##write data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 424 ---
demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 425 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust

--- Chunk 426 ---
demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 427 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust

--- Chunk 428 ---
response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 429 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust

--- Chunk 430 ---
##write data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 431 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 432 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 433 ---
ds 4300 amazon ec2 lambda mark fontenot phd northeastern university based part material gareth eagars data engineering aws packt publishing ec2 ec2 ec2 elastic cloud compute scalable virtual computing cloud many many instance types available payasyougo model pricing multiple different operating systems features ec2 elasticity easily programmatically scale instances needed use one standard amis provide ami preconfig needed easily integrates many services s3 rds etc ami amazon machine image ec2 lifecycle launch starting instance first time chosen configuration startstop temporarily suspend usage without deleting instance terminate permanently delete instance reboot restart instance without sling data root volume store data instance store temporary highspeed storage tied instance lifecycle efs elastic file system support shared file storage ebs elastic block storage persistent blocklevel storage s3 large data set storage ec2 backups even common ec2 use cases web hosting run websiteweb server associated apps data processing vm anything data possible programming language machine learning train models using gpu instances disaster recovery backup critical workloads infrastructure cloud lets spin ec2 instance lets spin ec2 instance lets spin ec2 instance ubuntu vm commands initial user ubuntu access super user commands sudo package manager apt kind like homebrew choco update packages installed sudo apt update sudo apt upgrade miniconda ec2 make sure youre logged ec2 instance lets install miniconda curl httpsrepoanacondacomminicondaminiconda3latestlinuxx86 _ 64sh bash miniconda3latestlinuxx86 _ 64sh installing using streamlit log ec2 instance log back make sure pip available pip version install streamlit sklearn pip install streamlit scikitlearn make directory small web app mkdir web cd web basic streamlit app nano testpy add code left ctrlx save exit streamlit run testpy import streamlit st def main sttitlewelcome streamlit app stwrite data sets stwrite data set 01 data set 02 data set 03 stwriten stwrite goodbye _ _ name _ _ _ _ main _ _ main opening streamlit port browser aws lambda lambdas lambdas provide serverless computing automatically run code response events relieves manage servers worry code pay execution time idle compute time different ec2 lambda features eventdriven execution triggered many different events aws supports large number runtimes python java nodejs etc highly integrated aws services extremely scalable rapidly adjust demands works addupload code aws mgmt console configure event sources watch lambda run one event sources fires event lets make one making lambda creating function sample code edit code deploy code test

--- Chunk 434 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming

--- Chunk 435 ---
languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyou

--- Chunk 436 ---
##rstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker

--- Chunk 437 ---
create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre

--- Chunk 438 ---
drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300

--- Chunk 439 ---
collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 440 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming

--- Chunk 441 ---
binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb

--- Chunk 442 ---
##match problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongo

--- Chunk 443 ---
relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix

--- Chunk 444 ---
create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre

--- Chunk 445 ---
dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017

--- Chunk 446 ---
return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 447 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming

--- Chunk 448 ---
values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mis

--- Chunk 449 ---
languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyou

--- Chunk 450 ---
##match problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongo

--- Chunk 451 ---
##rstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker

--- Chunk 452 ---
##db service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _

--- Chunk 453 ---
create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre

--- Chunk 454 ---
_ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont

--- Chunk 455 ---
drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300

--- Chunk 456 ---
return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 457 ---
collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 458 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongo

--- Chunk 459 ---
##db service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300

--- Chunk 460 ---
collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 461 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongo

--- Chunk 462 ---
relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017

--- Chunk 463 ---
return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 464 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongo

--- Chunk 465 ---
##rstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont

--- Chunk 466 ---
drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 467 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300

--- Chunk 468 ---
collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 469 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300

--- Chunk 470 ---
getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 471 ---
ds 4300 document databases mongodb mark fontenot phd northeastern university material used permission dr rachlin thanks document database document database nonrelational database stores data structured documents usually json designed simple flexible scalable json json javascript object notation lightweight datainterchange format easy humans read write easy machines parse generate json built two structures collection namevalue pairs various languages operationalized object record struct dictionary hash table keyed list associative array ordered list values languages operationalized array vector list sequence two universal data structures supported virtually modern programming languages thus json makes great data interchange format json syntax httpswwwjsonorgjsonenhtml binary json bson bson binary json binaryencoded serialization jsonlike document structure supports extended types part basic json eg date binarydata etc lightweight keep space overhead minimum traversable designed easily traversed vitally important document db efficient encoding decoding must efficient supported many modern programming languages xml extensible markup language precursor json data exchange format xml css web pages separated content formatting structurally similar html tag set extensible xmlrelated toolstechnologies xpath syntax retrieving specific elements xml doc xquery query language interrogating xml documents sql xml dtd document type definition language describing allowed structure xml document xslt extensible stylesheet language transformation tool transform xml formats including nonxml formats html document databases document databases address impedance mismatch problem object persistence oo systems relational dbs structure data oo programming inheritance composition types save complex object relational database basically deconstruct structure document selfdescribing wellaligned apps use jsonxml transport layer mongodb mongodb started 2007 doubleclick acquired google 3 veterans realized limitations relational databases serving 400000 ads per second mongodb short humongous database mongodb atlas released 2016 documentdb service httpswwwmongodbcomcompanyourstory mongodb structure database collection collection b collection c document 1 document 2 document 3 document 1 document 2 document 3 document 1 document 2 document 3 mongodb documents predefined schema documents needed every document collection could different dataschema relational vs mongodocument db mongodb features rich query support robust support crud ops indexing supports primary secondary indices document fields replication supports replica sets automatic failover load balancing built mongodb versions mongodb atlas fully managed mongodb service cloud dbaas mongodb enterprise subscriptionbased selfmanaged version mongodb mongodb community sourceavailable freetouse selfmanaged interacting mongodb mongosh mongodb shell cli tool interacting mongodb instance mongodb compass free opensource gui work mongodb database datagrip 3rd party tools every major language library interface mongodb pymongo python mongoose javascriptnode mongodb community edition docker create container map hostcontainer port 27017 give initial username password superuser e mongodb compass gui tool interacting mongodb instance download install load mflix sample data set compass create new database named mflix download mflix sample dataset unzip import json files users theaters movies comments new collections mflix database creating database collection mflix users create new db create new collection mongosh mongo shell find like select collectionfind _ _ _ _ _ _ _ _ filters projections mongosh find select users use mflix dbusersfind mongosh find select users name davos seaworth dbusersfindname davos seaworth filter mongosh find select movies rated pg pg13 dbmoviesfindrated pg pg13 mongosh find return movies released mexico imdb rating least 7 dbmoviesfind countries mexico imdbrating gte 7 mongosh find return movies movies collection released 2010 either least 5 awards genre drama dbmoviesfind year 2010 awardswins gte 5 genres drama comparison operators mongosh countdocuments many movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama mongosh project return names movies movies collection released 2010 either least 5 awards genre drama dbmoviescountdocuments year 2010 awardswins gte 5 genres drama name 1 _ id 0 1 return 0 dont return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300

--- Chunk 472 ---
return pymongo pymongo pymongo python library interfacing mongodb instances pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 getting database collection pymongo import mongoclient client mongoclient mongodbuser _ namepwlocalhost27017 db clientds4300 collection dbmycollection inserting single document db clientds4300 collection dbmycollection post author mark text mongodb cool tags mongodb python post _ id collectioninsert _ onepostinserted _ id printpost _ id count documents collection select count collection demodbcollectioncount _ documents

--- Chunk 473 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed

--- Chunk 474 ---
databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication la

--- Chunk 475 ---
##g refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order

--- Chunk 476 ---
b far future see ms b 10 seconds usually mr

--- Chunk 477 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed

--- Chunk 478 ---
##emand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients

--- Chunk 479 ---
##hronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically

--- Chunk 480 ---
##write consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 481 ---
b far future see ms b 10 seconds usually mr

--- Chunk 482 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed

--- Chunk 483 ---
vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication sync

--- Chunk 484 ---
databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication la

--- Chunk 485 ---
##hronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically

--- Chunk 486 ---
##g refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order

--- Chunk 487 ---
switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 488 ---
b far future see ms b 10 seconds usually mr

--- Chunk 489 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically

--- Chunk 490 ---
switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 491 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically

--- Chunk 492 ---
##write consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 493 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically

--- Chunk 494 ---
##g refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 495 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 496 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 497 ---
ds 4300 replicating data mark fontenot phd northeastern university material used permission dr rachlin thanks distributing data benefits scalability high throughput data volume readwrite load grows beyond capacity single machine fault tolerance high availability application needs continue working even one machines goes latency users different parts world want give fast performance distributed data challenges consistency updates must propagated across network application complexity responsibility reading writing data distributed environment often falls application vertical scaling shared memory architectures geographically centralized server fault tolerance via hotswappable components vertical scaling shared disk architectures machines connected via fast network contention overhead locking limit scalability highwrite volumes ok data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures node cpu memory disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates data main partitions subset data replication common strategies replication single leader model multiple leader model leaderless model distributed databases usually adopt one strategies leaderbased replication writes clients go leader leader sends replication info followers followers process instructions leader clients read either leader followers leaderbased replication write could sent one followers leader leaderbased replication common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq replication info transmitted followers synchronous vs asynchronous replication synchronous leader waits response follower asynchronous leader doesnt wait confirmation synchronous asynchronous happens leader fails challenges pick new leader node consensus strategy perhaps based updates use controller node appoint new leader configure clients start writing new leader happens leader fails challenges asynchronous replication used new leader may writes recover lost writes simply discard old leader recovers avoid multiple leaders receiving conflicting data split brain way resolve conflicting requests leader failure detection optimal timeout tricky replication lag refers time takes writes leader reflected followers synchronous replication replication lag causes writes slower system brittle num followers increases asynchronous replication maintain availability cost delayed eventual consistency delay called inconsistency window replication lag readafterwrite consistency scenario youre adding comment reddit post click submit back main post comment show less important users see comment immediately implementing readafterwrite consistency method 1 modifiable data clients perspective always read leader implementing readafterwrite consistency method 2 dynamically switch reading leader recently updated data example policy requests within one minute last update come leader create challenges created followers would proximal users route requests distant leaders reading modifiable data monotonic read consistency monotonic read anomalies occur user reads values order multiple followers monotonic read consistency ensures user makes multiple reads read older data previously reading newer data consistent prefix reads reading data order occur different partitions replicate data different rates global write consistency consistent prefix read guarantee ensures sequence writes happens certain order anyone reading writes see appear order b far future see ms b 10 seconds usually mr

--- Chunk 498 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read

--- Chunk 499 ---
figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance

--- Chunk 500 ---
amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need

--- Chunk 501 ---
something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary

--- Chunk 502 ---
network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 503 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read

--- Chunk 504 ---
state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id

--- Chunk 505 ---
##uelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values

--- Chunk 506 ---
##er _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling

--- Chunk 507 ---
something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary

--- Chunk 508 ---
running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 509 ---
system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 510 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read

--- Chunk 511 ---
operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybl

--- Chunk 512 ---
figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance

--- Chunk 513 ---
##uelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values

--- Chunk 514 ---
amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need

--- Chunk 515 ---
sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases

--- Chunk 516 ---
something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary

--- Chunk 517 ---
relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance

--- Chunk 518 ---
network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 519 ---
system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 520 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values

--- Chunk 521 ---
sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 522 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values

--- Chunk 523 ---
##er _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 524 ---
system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 525 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values

--- Chunk 526 ---
amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance

--- Chunk 527 ---
network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 528 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 529 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 530 ---
ds 4300 moving beyond relational model mark fontenot phd northeastern university benefits relational model mostly standard data model query language acid compliance second atomicity consistency isolation durability works well highly structured data handle large amounts data well understood lots tooling lots experience relational database performance many ways rdbms increases efficiency indexing topic focused directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication partitioning transaction processing transaction sequence one crud operations performed single logical unit work either entire sequence succeeds commit entire sequence fails rollback abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction treated atomic unit fully executed parts executed consistency transaction takes database one consistent state another consistent state consistent state data meets integrity constraints acid properties isolation two transactions t1 t2 executed time affect t1 t2 reading data problem t1 reading data t2 may writing result dirty read nonrepeatable read phantom reads isolation dirty read figure httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read transaction t1 able read row modified another transaction t2 hasnt yet executed commit isolation nonrepeatable read figure httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries single transaction t1 execute select get different values another transaction t2 changed data committed isolation phantom reads figure httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads transaction t1 running another transaction t2 adds deletes rows set t1 using example transaction transfer delimiter create procedure transfer sender _ id int receiver _ id int amount decimal102 begin declare rollback _ message varchar255 default transaction rolled back insufficient funds declare commit _ message varchar255 default transaction committed successfully start transaction start transaction attempt debit money account 1 update accounts set balance balance amount account _ id sender _ id attempt credit money account 2 update accounts set balance balance amount account _ id receiver _ id continued next slide example transaction transfer continued previous slide check sufficient funds account 1 simulate condition insufficient funds select balance accounts account _ id sender _ id 0 roll back transaction insufficient funds rollback signal sqlstate 45000 45000 unhandled userdefined error set message _ text rollback _ message else log transactions sufficient funds insert transactions account _ id amount transaction _ type values sender _ id amount withdrawal insert transactions account _ id amount transaction _ type values receiver _ id amount deposit commit transaction commit select commit _ message result end end delimiter acid properties durability transaction completed committed successfully changes permanent even event system failure committed transactions preserved info transactions see kleppmann book chapter 7 relational databases may solution problems sometimes schemas evolve time apps may need full strength acid compliance joins expensive lot data semistructured unstructured json xml etc horizontal scaling presents challenges apps need something performant real time low latency systems scalability conventional wisdom scale vertically bigger powerful systems demands highavailability make necessary scale type distributed computing model scaling easier need really modify architecture practical financial limits however modern systems make horizontal scaling less problematic distributed data scaling distributed system collection independent computers appear users one computer andrew tennenbaum characteristics distributed systems computers operate concurrently computers fail independently shared global clock distributed storage 2 directions single main node distributed data stores data stored 1 node typically replicated ie block data available n nodes distributed databases relational nonrelational mysql postgresql support replication sharding cockroachdb new player scene many nosql systems support one models remember network partitioning inevitable network failures system failures overall system needs partition tolerant system keep running even w network partition cap theorem cap theorem cap theorem states impossible distributed data store simultaneously provide two following three guarantees consistency every read receives recent write error thrown availability every request receives nonerror response guarantee response contains recent write partition tolerance system continue operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user db identical view data given instant availability event failure database remains operational partition tolerance database maintain operations event networks failing two segments distributed system note definition consistency cap different acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds latest data every request gets response may able deal network issues consistency partition tolerance system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 531 ---
system responds data distributed store always latest else data request dropped availability partition tolerance system always sends responds based distributed store may absolute latest data cap reality really saying limit number faults requests directed server insist serving every request possibly consistent interpreted must always give something consistency availability tolerance failure

--- Chunk 532 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl

--- Chunk 533 ---
case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 534 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl

--- Chunk 535 ---
##right lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl

--- Chunk 536 ---
50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 537 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl

--- Chunk 538 ---
##d node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40

--- Chunk 539 ---
case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 540 ---
50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 541 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 542 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 543 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 544 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 545 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 546 ---
avl trees balancing rotations example avl tree selfbalancing binary search tree bst maintains balance ensuring height difference balance factor left right subtrees node exceed one property guarantees efficient operations insertion deletion lookup time complexity olog n imbalance cases rotations preserve balance insertions deletions avl trees utilize rotations rectify four primary imbalance scenarios 1 leftleft case occurs node becomes unbalanced due insertion left subtree left child imbalance corrected performing right rotation unbalanced node example rotation z x right rotation z x z 2 rightright rr case occurs node becomes unbalanced due insertion right subtree right child imbalance corrected performing left rotation unbalanced node example rotation z x left rotation z z x 3 leftright lr case occurs node becomes unbalanced due insertion right subtree left child imbalance corrected performing left rotation left child followed right rotation unbalanced node example rotations z x left rotation right rotation z x z 4 rightleft rl case occurs node becomes unbalanced due insertion left subtree right child imbalance corrected performing right rotation right child followed left rotation unbalanced node example rotations z x right rotation left rotation z x z insertion example consider inserting following sequence numbers empty avl tree 10 20 30 40 50 25 1 insert 10 10 2 insert 20 10 20 3 insert 30 10 20 30 forms rr case node 10 perform left rotation 10 20 10 30 4 insert 40 20 10 30 40 5 insert 50 20 10 30 40 50 forms rr case node 30 perform left rotation 30 20 10 40 30 50 6 insert 25 20 10 40 30 50 25 forms lr case node 40 perform right rotation 40 followed left rotation 20 30 20 40 10 25 50 tree balanced adhering avl properties visual explanation avl tree insertions rotations might find video helpful avl tree insertion example

--- Chunk 547 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree

--- Chunk 548 ---
answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes

--- Chunk 549 ---
required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irrevers

--- Chunk 550 ---
##ible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure

--- Chunk 551 ---
consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used

--- Chunk 552 ---
feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3

--- Chunk 553 ---
higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field

--- Chunk 554 ---
contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 555 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree

--- Chunk 556 ---
list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference

--- Chunk 557 ---
tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction

--- Chunk 558 ---
##d indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write

--- Chunk 559 ---
##ible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure

--- Chunk 560 ---
distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume

--- Chunk 561 ---
vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrb

--- Chunk 562 ---
way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql

--- Chunk 563 ---
higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field

--- Chunk 564 ---
3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 565 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree

--- Chunk 566 ---
##ocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b

--- Chunk 567 ---
answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes

--- Chunk 568 ---
tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction

--- Chunk 569 ---
required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irrevers

--- Chunk 570 ---
relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database

--- Chunk 571 ---
##ible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure

--- Chunk 572 ---
consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server

--- Chunk 573 ---
consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used

--- Chunk 574 ---
vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrb

--- Chunk 575 ---
feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3

--- Chunk 576 ---
##y incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles

--- Chunk 577 ---
higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field

--- Chunk 578 ---
movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 579 ---
contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 580 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction

--- Chunk 581 ---
relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used

--- Chunk 582 ---
feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 583 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction

--- Chunk 584 ---
##d indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume

--- Chunk 585 ---
vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field

--- Chunk 586 ---
3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 587 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction

--- Chunk 588 ---
required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server

--- Chunk 589 ---
consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles

--- Chunk 590 ---
higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 591 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used

--- Chunk 592 ---
feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 593 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used

--- Chunk 594 ---
traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 595 ---
ds 4300 spring 2025 sample midterm questions hw 04 sample exam questions test rag cheat sheet 1 difference list memory contiguously allocated list linked structures used difference list memory contiguously allocated list linked structures used first case data stored contiguously one memory location another second case data stored linked structures contiguous list elements address making easy access manipulate linked lists hand allow flexibility manipulating list allow recursive calls functions manipulate elements within flexibility allows efficient data manipulation provides opportunities optimizing algorithms 2 linked lists faster contiguouslyallocated lists llm answer given text providing question series notes topic related text material considered set instructions guidelines rather actual question notes sufficient answer given question provide specific information linked lists faster contiguouslyallocated lists terms performance answer linked lists faster storing new data within list references two neighboring values would change contiguously allocated list whole lists locations would moved order insert new value middle 3 add 23 avl tree imbalance case created inserting 23 30 25 35 20 computer answer imbalance case created inserting 23 avl tree answer lr imbalance created 23 inserted avl tree chroma imbalance case created inserting 23 two elements minimum value avl tree left leftmost child second node insert must avl _ height less equal max height siblings would 1 maximum height 3 leftmost childs max height right child must also avl _ height less equal min height siblings 1 minimum height 2 therefore way node value 23 inserted avl tree due higher maxmin heights hence avl tree imbalance case created inserting 23 4 b tree better avl tree indexing large dataset context question refers rationale reason answer case b tree better option higher efficiency indexing large dataset due properties balancing minimizing number nodes required store data called reference item context larger problem b tree case reference concept balanced refers way b tree arranges nodes ensuring enough nodes accommodate data points minimizing number branches summary avl tree may better choice smaller datasets b tree suitable larger datasets large amounts data efficiently balance store data way minimizes number nodes required support datasets requirements 5 diskbased indexing important database systems diskbased indexing advanced technique used databases efficiently store retrieve data method organizing data separate regions storage device usually hard disk based relationships different elements within dataset primary benefit using diskbased indexing database system significantly reduce amount space needed storing large volumes data well improve query performance reducing need read traverse large tables storing frequently accessed data near origin diskbased indexing also enhance database scalability resilience 6 context relational database system transaction transaction relational database system process data operations coordinated ensure consistency integrity involves multiple users working set data time ensuring users changes consistent everyone elses sql transaction consists one operations change data database system operations executed either serially parallel must complete successfully new transactions begin 7 succinctly describe four components acid compliant transactions yes provide succinct detailed answer question regarding four components acid atomicity consistency isolation durability completing transactions components 1 atomicity component ensures update insert operation cant interrupted concurrent reads writes guarantees write operation atomic irreversible one read operation fails writing complete data rolled back previous state 2 consistency component determines changes applied multiple operations performed single database table consistent operations always succeed result consistent data model inconsistent operations fail inconsistent results 3 isolation component ensures reads writes different tables isolated prevents simultaneous read write access table lead errors inconsistencies 4 durability component describes changes applied multiple operations performed single database instance durable operations always succeed result permanent data nondurable operations result change data summary four components acid atomicity consistency isolation durability ensure transactions database consistently execute expected data model consistent across operations 8 cap principle make sense applied singlenode mongodb instance cap consistency availability partition tolerance principle designed ensure operations performed single node cluster able provide consistency availability partition tolerance cap theorem states properties achieved designing systems based least three distinct concepts 1 consistency ensuring operations performed node cluster produce result across nodes system 2 availability providing access data resources even nodes available reason 3 partition tolerance ensuring data resources accessed multiple partitions shards database cluster applied singlenode mongodb instance cap principle may valid ensure consistency availability partition tolerance principle guarantees least one node system perform operations without affected failures errors nodes multinode mongodb instance concepts still achieved may require complex architecture management ensure consistency availability partition tolerance 9 describe differences horizontal vertical scaling horizontal scaling hscaling refers expanding number servers computing resources available handle increasing traffic without change total number servers computing resources done adding additional server instances typically doubling number servers contrast vertical scaling vscaling involves adjusting size configuration individual server instances typically increasing number virtual machines assigned server increasing physical memory available per server vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used

--- Chunk 596 ---
vscaling done way affect total number servers computing resources summary hscaling increases capacity performance database system adding additional servers maintaining level reliability availability hand vscaling involves adjusting server configuration without expanding total number servers changing overall size architecture system ensuring still handle high volume traffic 10 briefly describe keyvalue store used feature store keyvalue store kv store type feature store allows businesses store retrieve data simple yet versatile way enables organizations store manage different types data text numbers images files without worry storing managing metadata keyvalue store used feature store provides central location storing accessing specific features attributes business data using kv store businesses easily access commonly used features attributes keeping nonessential data sight additionally features accessed various apis custom endpoints meet specific needs summary keyvalue store provides efficient scalable way storing accessing data making valuable feature store organization 11 redis originally released redis initially released 2009 12 redis difference inc incr commands redis two different commands updating integer sorted set b 1 inc increments value 1 c 2 incrby incrementing value given argument ie 1 2 difference commands first command increments keys integer value second command adds numeric value keys value perform action different syntax 13 benefits bson json mongodb 1 highperformance efficient bson bson object notation optimized format representing documents mongodb providing faster read write speeds json javascript object notation b 2 lower memory usage bson compressed stored binary format use less memory json leads significant performance improvements json mongodb c 3 higher scalability bson much larger capacity storing large amounts data compared json enables faster efficient querying joins secondary indexes 4 indexing support bson supports indexing key fields making easier search sort mongodb collections e 5 comparison sql nosql many cases bson efficient alternative sql nosql databases like cassandra redis storing large amounts data f 6 faster performance bson shown outperform json benchmarks suggests may better choice certain circumstances 14 write mongo query based movies data set returns titles movies released 2010 2015 suspense genre write mongo query return titles movies suspense genre released 2010 2015 use following steps 1 define collection want query case using movies collection within db database use db 2 define query object contain fields filters want apply query dbmoviesfind 3 specify search parameters example interested movies released 2010 2015 passing date range object slice operator dbmoviesfind _ id 0 title 1 release _ date gte new date20100101 lte new date 4 run query return documents movies collection title field contains suspense genres released 2010 2015 dbmoviesfind 15 nin operator mean mongo query niin operator mongo query used search documents based corresponding field values keyword ni represents logical operator returns documents satisfy specified condition

--- Chunk 597 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high

--- Chunk 598 ---
failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed

--- Chunk 599 ---
updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups

--- Chunk 600 ---
realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use

--- Chunk 601 ---
incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small

--- Chunk 602 ---
issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined

--- Chunk 603 ---
operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logari

--- Chunk 604 ---
##thmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff

--- Chunk 605 ---
distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka

--- Chunk 606 ---
flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees

--- Chunk 607 ---
allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 608 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high

--- Chunk 609 ---
multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2

--- Chunk 610 ---
eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector

--- Chunk 611 ---
client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags

--- Chunk 612 ---
realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use

--- Chunk 613 ---
decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster

--- Chunk 614 ---
jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator

--- Chunk 615 ---
##e 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimi

--- Chunk 616 ---
operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logari

--- Chunk 617 ---
5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes

--- Chunk 618 ---
c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user

--- Chunk 619 ---
availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipeline

--- Chunk 620 ---
flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees

--- Chunk 621 ---
writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 622 ---
example indexing improves mongodb sql queries

--- Chunk 623 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high

--- Chunk 624 ---
requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier

--- Chunk 625 ---
failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed

--- Chunk 626 ---
eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector

--- Chunk 627 ---
updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups

--- Chunk 628 ---
json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initial

--- Chunk 629 ---
realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use

--- Chunk 630 ---
##izes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared

--- Chunk 631 ---
incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small

--- Chunk 632 ---
jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator

--- Chunk 633 ---
issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined

--- Chunk 634 ---
used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbase

--- Chunk 635 ---
operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logari

--- Chunk 636 ---
##d indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency

--- Chunk 637 ---
##thmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff

--- Chunk 638 ---
c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user

--- Chunk 639 ---
distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka

--- Chunk 640 ---
_ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data

--- Chunk 641 ---
flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees

--- Chunk 642 ---
way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like

--- Chunk 643 ---
allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 644 ---
example indexing improves mongodb sql queries

--- Chunk 645 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector

--- Chunk 646 ---
json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small

--- Chunk 647 ---
issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency

--- Chunk 648 ---
c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees

--- Chunk 649 ---
allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 650 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector

--- Chunk 651 ---
client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster

--- Chunk 652 ---
jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logari

--- Chunk 653 ---
5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipeline

--- Chunk 654 ---
flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 655 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector

--- Chunk 656 ---
updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared

--- Chunk 657 ---
incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbase

--- Chunk 658 ---
operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user

--- Chunk 659 ---
distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like

--- Chunk 660 ---
allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 661 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small

--- Chunk 662 ---
issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees

--- Chunk 663 ---
allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 664 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small

--- Chunk 665 ---
queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads

--- Chunk 666 ---
way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

--- Chunk 667 ---
horizontal vs vertical scaling horizontal vertical scaling refer different ways handling increased system load computing database management horizontal scaling scaling definition involves adding machines eg servers database nodes distribute load works instead upgrading single machine multiple machines handle workload uses load balancers distribute requests among multiple instances common distributed systems eg cloud computing nosql databases like mongodb cassandra pros fault tolerance one server fails others still work better handling massive scaling used largescale web apps like google facebook scaled infinitely microservices clusters cons complex setup requires load balancing network configuration coordination overhead vertical scaling scaling definition involves upgrading existing machine eg adding cpu ram disk works instead adding machines single machine made powerful common relational databases eg mysql postgresql monolithic applications pros simpler need multiple servers load balancing easier implement legacy systems cons limited hardware constraints cant scale infinitely single point failure server crashes everything stops become expensive highend servers cost lot comparison table feature horizontal scaling scale vertical scaling scale method add machines distributed upgrade single machine fault tolerance high failure one node doesnt stop system low single machine failure critical cost costefficient scale expensive highend hardware complexity complex needs load balancing distributed databases simpler limited scalability use case largescale apps google facebook aws singleserver apps smaller systems choose use horizontal scaling web applications microservices nosql databases cloud computing use vertical scaling smaller applications traditional relational databases simpler deployments keyvalue store used feature store storing precomputed realtime features machine learning models key represents unique identifier eg user _ id product _ id session _ id value stores feature vectors attributes associated key eg age 25 purchase _ history 10 avg _ spend 505 works feature store 1 feature storage keyvalue store holds precomputed ml features fast retrieval 2 realtime lookups ml models quickly fetch feature vectors querying key 3 low latency serving since keyvalue stores optimized fast readswrites eg redis dynamodb rocksdb support realtime inference 4 feature updates features periodically refreshed updated real time based event streams example use case recommendation system user visits website user _ id used fetch relevant features eg past clicks preferred categories keyvalue store allowing model generate personalized recommendations instantly import redis import json connect redis redis _ client redisredishostlocalhost port6379 db0 decode _ responsestrue example feature data user _ id 123 user _ features age 25 purchase _ history 10 avg _ spend 505 preferred _ category electronics store feature vector json redis redis _ clientsetuser123 jsondumpsuser _ features printuser features stored successfully retrieve user features redis user _ data redis _ clientgetuser123 user _ data user _ features jsonloadsuser _ data printretrieved user features user _ features use features ml model modelpredictuser _ featuresage user _ featuresavg _ spend else printuser found feature store use redis feature store low latency fast keyvalue lookups realtime ml inference scalability handle millions readswrites efficiently persistence optionally persists data needed streaming support integrated kafka realtime feature updates use case example realtime fraud detection user makes transaction behavioral features eg avg transaction amount past fraud flags fetched redis features passed ml model predict fraud probability realtime redis correct command incrementing numeric value incr inc exist incr command usage incr key function increments value numeric key 1 default behavior key exist redis initializes 0 incrementing example set counter 10 incr counter get counter output 11 increment variants incrby key amount increments specific value incrbyfloat key amount increments floatingpoint number decr key decrements 1 decrby key amount decrements specific value example incrby incrby counter 5 get counter output 16 doesnt inc work inc valid redis commandif try use redis return error inc counter error error err unknown command inc summary use incr increment integer key 1 use incrby incrbyfloat custom increments inc exist redis bson binary json data format used mongodb storing exchanging data several advantages traditional json 1 efficient storage bson supports binary encoding reduces data size speeds readwrite operations compared jsons plain text format 2 rich data types bson supports additional data types json date stored integer timestamp binary data useful storing images files encrypted data 32bit 64bit integers compared jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small

--- Chunk 668 ---
jsons reliance floatingpoint numbers objectid unique efficient identifier 3 faster parsing since bson binary format mongodb parse process efficiently plaintext json 4 indexing optimization bson allows optimized indexing mongodb enabling faster queries 5 document size efficiency bson includes length prefixes strings documents allows faster scanning retrieval fields bson sometimes slightly larger json due metadata padding performance advantages make wellsuited mongodbs storage querying operations mongodb query provided small issue year field compared number string heres correct query dbmoviesfind genre suspense year gte 2010 lte 2015 title 1 _ id 0 fixes explanation 1 data type correction original query year gte 2010 lte 2015 2010 2015 strings numbers gte 2010 lte 2015 2 simplified operator needed multiple conditions within object implicitly anded 3 projection title 1 _ id 0 ensures movie titles returned excluding default _ id field expected output example title movie title movie b title movie c mongodb nin operator used filter documents fields value specified array values opposite syntax field nin value1 value2 returns documents field contain values array example usage 1 excluding specific values find users boston new york dbusersfind city nin boston new york query retrieves users whose city neither boston new york 2 checking field absence field exist document nin also match example dbproductsfind category nin electronics clothing returns products category neither electronics clothing category field missing key points nin acts negation also matches documents specified field exist combined operators complex queries would like example mongodb dataset diskbased indexing diskbased indexing refers use data structures stored disk enable efficient searching retrieval records database unlike inmemory indexing relies ram diskbased indexing optimized persistent storage minimizing disk io operations improve query performance diskbased indexing important 1 efficient query performance indexes reduce need full table scans allowing databases quickly locate records even large datasets 2 scalability large databases often exceed available ram diskbased indexing ensures efficient searches without requiring data loaded memory 3 reduced disk io indexes store references pointers actual data locations minimizing number disk reads needed fetch records 4 faster sorting joins many database operations like sorting joining tables benefit indexed access rather sequential scanning 5 support range queries indexes enable efficient retrieval records within specified range eg age 30 age 50 common diskbased index structures 1 btrees balanced trees used databases like mysql postgresql btrees allow logarithmic time complexity lookups insertions deletions 2 b trees variation btrees stores data leaf nodes optimizing range queries sequential access 3 hash indexes used quick lookups based exact matches seen nosql databases 4 inverted indexes common search engines textbased databases eg elasticsearch fast fulltext searching would like specific example related mongodb another database 1 cap principle make sense applied singlenode mongodb instance cap theorem states distributed database system achieve two three properties consistency c every read receives recent write error availability every request receives response even might latest data partition tolerance p system continues function even network failures occur nodes cap doesnt apply singlenode mongodb instance singlenode mongodb instance distributed system meaning multiple nodes communicating network 1 network partitions p since one node theres risk network failures splitting system disconnected parts concept partition tolerance apply 2 always consistent c available singlenode setup every read gets latest write ensuring strong consistency system always available long node running 3 cap tradeoff distributed systems cap theorem applies multiple nodes communicating network cases network partition occurs system must choose consistency availability conclusion singlenode mongodb instance cap isnt relevant partitions consistency availability maintained however replicated sharded mongodb setup cap apply tradeoffs consistency availability must considered network failures occur would like example cap applies mongodb replica set keyvalue store used feature store storing serving precomputed feature values machine learning models fast scalable way heres works 1 storing features key represents unique entity eg user _ id product _ id value structured object containing entitys features eg users purchase history product rating engagement scores example using redis dynamodb user123 age 25 purchase _ count 42 avg _ spend 15075 2 retrieving features model inference making predictions model queries feature store key eg user123 get latest precomputed feature values enables lowlatency access features critical realtime ml applications 3 updating features features updated periodically via batch processing etl pipelines realtime streaming kafka flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data

--- Chunk 669 ---
flink keyvalue stores provide fast writes ensuring feature store remains date use keyvalue store feature store lowlatency lookups ideal realtime inference scalable storage retrieval large datasets efficient updates using simple keybased writes easy integration ml pipelines would like example using redis feature store diskbased indexing diskbased indexing technique used database systems efficiently store retrieve data disk storage since accessing disk significantly slower accessing memory diskbased indexing structures designed minimize disk io organizing data way enables fast lookups inserts updates diskbased indexing important 1 optimized query performance indexes reduce need full table scans allowing databases quickly locate records 2 efficient disk io structuring data efficiently diskbased indexes reduce number disk reads writes improving performance 3 scalability large datasets often fit memory making diskbased indexing essential handling billions records 4 faster sorting joins indexes improve performance queries require sorting filtering joining multiple tables 5 support range queries indexes like btrees allow efficient retrieval data within range eg age 30 50 common diskbased indexing structures 1 btrees b trees used relational databases mysql postgresql balance fast lookups efficient sequential access 2 hash indexes used exactmatch lookups efficient range queries 3 inverted indexes common text search engines eg elasticsearch fast fulltext search conclusion diskbased indexing essential managing large datasets efficiently ensuring database queries remain fast even data exceeds available ram would like example indexing improves mongodb sql queries

